{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available LLMs: (24): llama-3.3-8b llama-4-scout llama-4-mav gpt-oss-20b gpt-oss-120b qwen3-8b qwen3-14b qwen3-32b qwen3-30b-a3b-2507 qwen3-235b-a22b-2507 gemma-3-12b gemma-3-27b mistral-small-3.2-24b mistral-medium-3 llama-3.1-70b llama-3.3-70b llama-3.1-405b grok-4-fast deepseek-chat-v3.1 deepseek-r1-0528 gemini-2.5-flash gemini-2.5-flash-grounded gemini-2.5-pro gemini-2.5-pro-grounded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espinl/.conda/envs/py311_llmscholar/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from libs import io\n",
    "from libs import constants\n",
    "from libs import vis\n",
    "from libs.visuals import grid\n",
    "from libs import helpers\n",
    "# from libs.metrics import aggregators\n",
    "from libs.metrics import helpers as helpers_metrics\n",
    "from libs.visuals import polar_infra\n",
    "from libs.visuals import constants as grid_constants\n",
    "# from libs import latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. read summaries\n",
    "2. read valid responses\n",
    "3. read factuality\n",
    "4. read similarities\n",
    "5. summarize metrics of interest per response (some will need summaries, others factuality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "APS_OA_DATA_TAR_GZ = '../../../APS/data/final_dataset.tar.gz'\n",
    "APS_OS_DISCIPLINE_DEMOGRAPHICS = '../../results/interventions/metadata/disciplines_author_demographics.csv'\n",
    "FN_COAUTHORSHIP = '../../../APS/results/augmented_aps/coauthorships.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_PATH = '../../results/interventions/summaries'\n",
    "VALID_RESPONSES_PATH = '../../results/interventions/valid_responses'\n",
    "FACTUALITY_PATH = '../../results/interventions/factuality'\n",
    "SIMILARITY_PATH = '../../results/interventions/similarities'\n",
    "\n",
    "PLOTS_PATH = '../../results/interventions/plots'\n",
    "TABLES_PATH = '../../results/interventions/tables'\n",
    "LATEX_PATH = '../../results/interventions/latex'\n",
    "\n",
    "io.validate_path(PLOTS_PATH)\n",
    "io.validate_path(TABLES_PATH)\n",
    "io.validate_path(LATEX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.sns_reset()\n",
    "vis.sns_paper_style(font_scale=1.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72117, 20), (3365532, 17), (3365532, 36), (513, 32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the summary data for each model (all outputs)\n",
    "df_summary_all = io.pd.concat([io.read_csv(io.path_join(SUMMARY_PATH, f\"experiments_{model}.csv\"), low_memory=False) for model in constants.LLMS], ignore_index=True)\n",
    "df_valid_responses_all = io.pd.concat([io.read_csv(io.path_join(VALID_RESPONSES_PATH, f\"{model}.csv\"), index_col=0, low_memory=False) for model in constants.LLMS], ignore_index=True)\n",
    "df_factuality_author_all = io.pd.concat([io.read_csv(io.path_join(FACTUALITY_PATH, f\"{model}_author.csv\"), index_col=0, low_memory=False) for model in constants.LLMS], ignore_index=True)\n",
    "\n",
    "df_similarity_all = io.pd.DataFrame()\n",
    "for model in constants.LLMS:\n",
    "    for fn in io.glob.glob(io.path_join(SIMILARITY_PATH, f\"{model}_*.csv\")):\n",
    "        tmp = io.read_csv(fn, low_memory=False, index_col=0)\n",
    "        df_similarity_all = io.pd.concat([df_similarity_all, tmp], ignore_index=True)\n",
    "\n",
    "\n",
    "df_summary_all.shape, df_valid_responses_all.shape, df_factuality_author_all.shape, df_similarity_all.shape\n",
    "# (72117, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65997, 20), (3196771, 17), (3196771, 36))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter period for open-weight models\n",
    "# 2026-01-15 some models were not available (eg. gemma, qwen)\n",
    "# propietary models were available all the time (on different dates; we take them all)\n",
    "start_date = '2025-12-19'\n",
    "end_date = '2026-01-18'\n",
    "\n",
    "# filter out interventions\n",
    "query = \"((not model.str.contains('gemini') and date >= @start_date and date <= @end_date) or model.str.contains('gemini'))\"\n",
    "\n",
    "df_summary = df_summary_all.query(query).copy()\n",
    "df_valid_responses = df_valid_responses_all.query(query).copy()\n",
    "df_factuality_author = df_factuality_author_all.query(query).copy()\n",
    "df_similarity = df_similarity_all.query(query).copy()\n",
    "\n",
    "# shapes\n",
    "df_summary.shape, df_valid_responses.shape, df_factuality_author.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481012, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demographics\n",
    "df_all_authors_demographics = io.read_file_from_tar_gz_as_dataframe(APS_OA_DATA_TAR_GZ, constants.APS_OA_AUTHORS_DEMOGRAPHICS_FN)\n",
    "df_all_authors_demographics.rename(columns={'id_author':'id_author_oa'}, inplace=True)\n",
    "\n",
    "# scholarly stats\n",
    "df_all_authors_stats = io.read_file_from_tar_gz_as_dataframe(APS_OA_DATA_TAR_GZ, constants.APS_OA_AUTHORS_STATS_FN)\n",
    "df_all_authors_stats.rename(columns={'id_author':'id_author_oa'}, inplace=True)\n",
    "\n",
    "# gt (from APS)\n",
    "df_gt = df_all_authors_demographics[['id_author_oa','first_name','last_name','ethnicity','gender']].copy()\n",
    "df_gt = df_gt.merge(df_all_authors_stats[['id_author_oa','works_count','cited_by_count', 'rr1_rank_publications','rr1_rank_publications_percentile', 'rr2_rank_citations','rr2_rank_citations_percentile']], on='id_author_oa', how='left')\n",
    "df_gt = helpers.add_quantiles(df_gt)\n",
    "\n",
    "del df_all_authors_demographics\n",
    "del df_all_authors_stats\n",
    "\n",
    "# shapes\n",
    "df_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Male       44.432779\n",
       "Unknown    42.221192\n",
       "Female      8.772130\n",
       "Unisex      4.573898\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt.gender.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65997, 25), (3196771, 45))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding prominence metrics to recommended authors\n",
    "df_factuality_author = df_factuality_author.merge(df_gt[['id_author_oa', 'prominence_pub', 'prominence_cit']], on='id_author_oa', how='left')\n",
    "\n",
    "# adding infrastructure metadata\n",
    "df_summary = helpers.add_infrastructure_columns(df_summary)\n",
    "df_factuality_author = helpers.add_infrastructure_columns(df_factuality_author)\n",
    "df_similarity = helpers.add_infrastructure_columns(df_similarity)\n",
    "\n",
    "# shapes\n",
    "df_summary.shape, df_factuality_author.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the metric per attempt for ALL requests\n",
    "\n",
    "_ = helpers_metrics.load_per_attempt('validity_pct', df_summary, TABLES_PATH)\n",
    "_ = helpers_metrics.load_per_attempt('refusal_pct', df_summary, TABLES_PATH)\n",
    "_ = helpers_metrics.load_per_attempt('duplicates', df_factuality_author, TABLES_PATH)\n",
    "_ = helpers_metrics.load_per_attempt('consistency', df_factuality_author, TABLES_PATH)\n",
    "\n",
    "_ = helpers_metrics.load_per_attempt('factuality_author', df_factuality_author, TABLES_PATH)\n",
    "_ = helpers_metrics.load_per_attempt('connectedness_density', df_factuality_author, TABLES_PATH, df_similarity=df_similarity, metric_similarity='recommended_author_pairs_are_coauthors')\n",
    "_ = helpers_metrics.load_per_attempt('connectedness_entropy', df_factuality_author, TABLES_PATH, df_similarity=df_similarity, metric_similarity='normalized_component_entropy')\n",
    "_ = helpers_metrics.load_per_attempt('connectedness_components', df_factuality_author, TABLES_PATH, df_similarity=df_similarity, metric_similarity='normalized_n_components')\n",
    "_ = helpers_metrics.load_per_attempt('similarity_pca', df_factuality_author, TABLES_PATH, df_similarity=df_similarity, metric_similarity='scholarly_pca_similarity_mean')\n",
    "\n",
    "_ = helpers_metrics.load_per_attempt('diversity_gender', df_factuality_author, TABLES_PATH)\n",
    "_ = helpers_metrics.load_per_attempt('diversity_ethnicity', df_factuality_author, TABLES_PATH)\n",
    "_ = helpers_metrics.load_per_attempt('diversity_prominence_pub', df_factuality_author, TABLES_PATH)\n",
    "_ = helpers_metrics.load_per_attempt('diversity_prominence_cit', df_factuality_author, TABLES_PATH)\n",
    "\n",
    "_ = helpers_metrics.load_per_attempt('parity_gender', df_factuality_author, TABLES_PATH, gt=df_gt)\n",
    "_ = helpers_metrics.load_per_attempt('parity_ethnicity', df_factuality_author, TABLES_PATH, gt=df_gt)\n",
    "_ = helpers_metrics.load_per_attempt('parity_prominence_pub', df_factuality_author, TABLES_PATH, gt=df_gt)\n",
    "_ = helpers_metrics.load_per_attempt('parity_prominence_cit', df_factuality_author, TABLES_PATH, gt=df_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_llmscholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
