{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e652a2",
   "metadata": {},
   "source": [
    "# Data for Visualization Tool\n",
    "Auditing Algorithms using Network data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b6fb6",
   "metadata": {},
   "source": [
    "Note: It contains `version=0` (from `dev/_vis_workshop.ipynb` by `LE`) and `version=1` (from `dev/_vis_workshop_updates.ipynb` by `DB`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb1bbd",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003d52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218c1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270f9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from libs import constants as cons\n",
    "from libs import io \n",
    "from libs import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c83bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "APS_PATH = '/data/datasets/LLMScholar-Audits/APS'\n",
    "ROOT = '/data/datasets/LLMScholar-Audits/Auditor/backups/results_v2_arxiv'\n",
    "RESULTS = os.path.join(ROOT, 'vistool')\n",
    "FACT_TASKS = ['author', 'epoch', 'field', 'seniority']\n",
    "\n",
    "### SUBSET data (1 week):\n",
    "# VALID_DATE_RANGE = pd.date_range(start='2024-12-09', end='2024-12-15', freq='D')\n",
    "\n",
    "### ALL data (1 month): 2024-12-09 to 2025-01-08\n",
    "VALID_DATE_RANGE = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22bdff",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1166aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_MAPPING = {\n",
    "    'gemma2-9b': 'g2',\n",
    "    'mixtral-8x7b': 'mx',\n",
    "    'llama3-70b': 'l3_70',\n",
    "    'llama3-8b': 'l3_8',\n",
    "    'llama-3.1-8b': 'l31_8',\n",
    "    'llama-3.1-70b': 'l31_70'\n",
    "}\n",
    "\n",
    "# Task parameter abbreviations\n",
    "TASK_MAPPING = {\n",
    "    '1950s': '1950s',\n",
    "    'PER': 'per',\n",
    "    'top_5': 'top5',\n",
    "    '2000s': '2000s',\n",
    "    'CM&MP': 'cmmp',\n",
    "    'early_career': 'ec',\n",
    "    'senior': 'sr',\n",
    "    'top_100': 'top100',\n",
    "    'famous_female': 'twff',\n",
    "    'famous_male': 'twfm',\n",
    "    'fictitious_female': 'twficf',\n",
    "    'fictitious_male': 'twficm',\n",
    "    'movie_female': 'twmvf',\n",
    "    'movie_male': 'twmvm',\n",
    "    'politic_female': 'twpolf',\n",
    "    'politic_male': 'twpolm',\n",
    "    'random_female': 'twranf',\n",
    "    'random_male': 'twranm'\n",
    "}\n",
    "\n",
    "def _update_factuality_author(kind, task, df):\n",
    "    \"\"\"Update factuality author DataFrame with corrected fields.\"\"\"\n",
    "    if kind == 'factuality' and task == 'author':\n",
    "        # Corrected factuality based on APS presence\n",
    "        df['is_in_aps'] = df.id_author_oa.apply(lambda x: False if pd.isnull(x) else True)\n",
    "    return df\n",
    "\n",
    "def _update_factuality_epoch(kind, task, df):\n",
    "    \"\"\"Update factuality epoch DataFrame with corrected fields.\"\"\"\n",
    "    if kind == 'factuality' and task == 'epoch':\n",
    "        df['requested_epoch'] = df['task_param'].apply(lambda x: int(x[:-1]) if x in ['1950s', '2000s'] else x)\n",
    "        \n",
    "        # @TODO: Review this logic as it seems to be the same as fact_epoch_overlap\n",
    "        # df['fact_epoch_requested'] = (\n",
    "        #     df['year_first_publication'].notna() & \n",
    "        #     df['year_last_publication'].notna() &\n",
    "        #     ~((df['year_last_publication'] < df['requested_epoch']) | \n",
    "        #     (df['year_first_publication'] > df['requested_epoch'] + 10))\n",
    "        # )\n",
    "\n",
    "        df.drop(columns=['requested_epoch'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _add_runid(df):\n",
    "    # Format: {model_short}_{date_short}_{task_short}_{hour}\n",
    "    df['model_short'] = df['model'].map(MODEL_MAPPING)\n",
    "    df['date_short'] = df['date'].str.replace('2024-', '').str.replace('-', '')\n",
    "    df['task_short'] = df['task_param'].map(TASK_MAPPING)\n",
    "    df['time_short'] = df['time'].str.split(':').str[0]  # Extract hour (00, 08, 16)\n",
    "    df['run_id'] = df['model_short'] + '_' + df['task_short'] + '_' + df['date_short'] + '_' + df['time_short']\n",
    "    df.drop(columns=['model_short', 'date_short', 'task_short', 'time_short'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def _get_df_audit(kind='factuality', task='author', date_range=None):\n",
    "    \"\"\"Load all data into a single DataFrame.\"\"\"\n",
    "\n",
    "    if kind not in ['factuality', 'similarities']:\n",
    "        raise ValueError(f\"kind must be either 'factuality' or 'similarities'\")\n",
    "\n",
    "    if kind == 'factuality':\n",
    "        if task not in FACT_TASKS:\n",
    "            raise ValueError(f\"task must be either {', '.join(FACT_TASKS)}\")\n",
    "    elif kind == 'similarities':\n",
    "        if task not in cons.EXPERIMENT_TASKS:\n",
    "            raise ValueError(f\"task must be either {cons.EXPERIMENT_TASKS}\")\n",
    "        \n",
    "    df_rs = pd.DataFrame()\n",
    "    for fn in glob.glob(os.path.join(ROOT, kind, f'*{task}.csv')):\n",
    "        df = pd.read_csv(fn, index_col=0)\n",
    "        df['date_dt'] = pd.to_datetime(df['date'])\n",
    "\n",
    "        if date_range is not None:\n",
    "            df = df[(df['date_dt'] >= date_range[0]) & (df['date_dt'] <= date_range[-1])]\n",
    "\n",
    "        if 'llm_model' in df.columns:\n",
    "            df.loc[:,'_tmp_'] = df.loc[:,'llm_model']\n",
    "            df.loc[:, 'llm_model'] = df.loc[:, 'model']\n",
    "            df.loc[:, 'model'] = df.loc[:, '_tmp_']\n",
    "            df.rename(columns={'model':'model_fullname', 'llm_model':'model'}, inplace=True)\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"Skipping empty DataFrame for {fn}\")\n",
    "            continue\n",
    "\n",
    "        df.drop(columns=['date_dt', '_tmp_'], inplace=True, errors='ignore')\n",
    "        df_rs = pd.concat([df_rs, df])\n",
    "\n",
    "    # If task is author remove unnecesary fields\n",
    "    cols_to_remove = ['level_5']\n",
    "\n",
    "    if kind == 'factuality':\n",
    "        cols_to_remove.extend(['valid_attempt', 'model_fullname'])\n",
    "\n",
    "        if task == 'author':\n",
    "            cols_to_remove.extend(['fact_author_score', 'id_author_aps_list', 'ethnicity_dx', 'ethnicity_ec', 'ethnicity', 'gender', 'works_count', 'cited_by_count', 'h_index', 'i10_index', 'e_index', 'two_year_mean_citedness', 'year_first_publication', 'year_last_publication', 'academic_age', 'age_now', 'seniority_active', 'seniority_now'])\n",
    "        elif task == 'field':\n",
    "            cols_to_remove = ['fact_doi_score']\n",
    "\n",
    "    df_rs.drop(columns=cols_to_remove, inplace=True, errors='ignore')\n",
    "        \n",
    "    # Updates\n",
    "    df_rs = _update_factuality_author(kind, task, df_rs)\n",
    "    df_rs = _update_factuality_epoch(kind, task, df_rs)\n",
    "\n",
    "    # create run ids\n",
    "    df_rs = _add_runid(df_rs)\n",
    "    \n",
    "    return df_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f203a",
   "metadata": {},
   "source": [
    "## Generating Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed9a21",
   "metadata": {},
   "source": [
    "### Factuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5489d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FACTUALITY\n",
    "def get_factuality_df(task='author', date_range=None):\n",
    "    \"\"\"Load all factuality data into a single DataFrame.\"\"\"\n",
    "    return _get_df_audit(kind='factuality', task=task, date_range=date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97169fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factuality DataFrame for author loaded with 138439 rows.\n",
      "Factuality DataFrame for epoch loaded with 11760 rows.\n",
      "Factuality DataFrame for field loaded with 15861 rows.\n",
      "Skipping empty DataFrame for /data/datasets/LLMScholar-Audits/Auditor/backups/results_v2_arxiv/factuality/gemma2-9b_seniority.csv\n",
      "Factuality DataFrame for seniority loaded with 10860 rows.\n"
     ]
    }
   ],
   "source": [
    "# Factuality\n",
    "for task in FACT_TASKS:\n",
    "    df_factuality = get_factuality_df(task=task, date_range=VALID_DATE_RANGE)\n",
    "    print(f\"Factuality DataFrame for {task} loaded with {len(df_factuality)} rows.\")\n",
    "    fn = io.path_join(RESULTS, 'audit', f'factuality_{task}.csv')\n",
    "    io.validate_path(fn)\n",
    "    df_factuality.to_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a1750a",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b60c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMILARITY SCORES\n",
    "def get_similarity_df(task='top-k', date_range=None):\n",
    "    \"\"\"Load all similarity scores into a single DataFrame.\"\"\"\n",
    "    return _get_df_audit(kind='similarities', task=task, date_range=date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f8dda34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity DataFrame for top_k loaded with 822 rows.\n",
      "Similarity DataFrame for field loaded with 831 rows.\n",
      "Similarity DataFrame for epoch loaded with 757 rows.\n",
      "Similarity DataFrame for seniority loaded with 752 rows.\n",
      "Similarity DataFrame for twins loaded with 4086 rows.\n"
     ]
    }
   ],
   "source": [
    "# Similarities\n",
    "for task in cons.EXPERIMENT_TASKS:\n",
    "    df_similarity = get_similarity_df(task=task, date_range=VALID_DATE_RANGE)\n",
    "    print(f\"Similarity DataFrame for {task} loaded with {len(df_similarity)} rows.\")\n",
    "    fn = io.path_join(RESULTS, 'audit', f'similarity_{task}.csv')\n",
    "    io.validate_path(fn)\n",
    "    df_similarity.to_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5684f",
   "metadata": {},
   "source": [
    "### Coauthorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88eb2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coauthors_and_authors(authors_in_llm_lst, fn_coauthors):\n",
    "    authors = set()\n",
    "    edge_list = set()\n",
    "\n",
    "    obj_coauthors = {int(item['openalex_id'].replace('A','')):item for item in io.read_list_of_dicts(fn_coauthors)}\n",
    "    aps_oa_mapping = {obj['id_author']:oa_id for oa_id, obj in obj_coauthors.items()}\n",
    "\n",
    "    for id_author_oa in authors_in_llm_lst:\n",
    "        id_author_oa = int(id_author_oa)\n",
    "        authors |= set([id_author_oa])\n",
    "\n",
    "        if id_author_oa in obj_coauthors:\n",
    "            oa_coauthors_ids = [aps_oa_mapping[aps_id] for aps_id in obj_coauthors[id_author_oa]['aps_co_authors'] if aps_id not in cons.NONE and pd.notna(aps_id)]\n",
    "            authors |= set(oa_coauthors_ids)    \n",
    "            edge_list |= set([f'{id_author_oa}\\t{coauthor_id}' for coauthor_id in oa_coauthors_ids])\n",
    "\n",
    "    return edge_list, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0519bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_coauthors = io.path_join(APS_PATH, 'results/organised_data/aps_coauthor_networks.json')\n",
    "authors_in_llm = pd.read_csv(io.path_join(RESULTS, 'audit', f'factuality_author.csv'))['id_author_oa'].dropna().values\n",
    "\n",
    "edge_list, authors = get_coauthors_and_authors(authors_in_llm, fn_coauthors)\n",
    "\n",
    "fn = io.path_join(RESULTS, 'ground_truth', f'coauthorships_edgelist.txt')\n",
    "io.validate_path(fn)\n",
    "io.save_list_to_file(edge_list, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e7b77",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5deca152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCA(df_stats, n_components=2):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    data = df_stats.copy()\n",
    "    data = data.fillna({'e_index':0, 'citations_per_paper_age':0}).replace({'e_index':cons.INF, 'citations_per_paper_age':cons.INF}, 0)\n",
    "    data = data.drop(columns=[c for c in data.columns if c.startswith('rr') and '_rank_' in c] + ['orcid', 'aps_years_of_activity'])\n",
    "    print(f\"Original number of features: {df_stats.shape[1]}, now: {data.shape[1]}\")\n",
    "\n",
    "    # Handle missing values (if any)\n",
    "    data = data.fillna(data.mean())\n",
    "    combined_data = data.copy()\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    data_normalized = scaler.fit_transform(data)\n",
    "    \n",
    "    # Apply dimensionality reduction (e.g., PCA)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_data = pca.fit_transform(data_normalized)\n",
    "\n",
    "    # Add reduced dimensions to the combined DataFrame\n",
    "    for i in range(n_components):\n",
    "        combined_data[f'dim{i+1}'] = reduced_data[:, i]\n",
    "        \n",
    "    # appending the results\n",
    "    results = {'reduction':combined_data, \n",
    "               'variance':pca.explained_variance_, \n",
    "               'variance_ratio':pca.explained_variance_ratio_}\n",
    "    # Get PC1 loadings\n",
    "    loadings = pd.DataFrame(pca.components_.T,     # Transpose to align features with PCs\n",
    "                            index=data.columns,    # Original feature names\n",
    "                            columns=[\"PC1\", \"PC2\"] # Principal components\n",
    "                            )\n",
    "        \n",
    "    return results, loadings\n",
    "\n",
    "def get_demographics(fn_demographics, fn_nobel_prize_winners, threshold=5):\n",
    "    df_demographics = pd.read_csv(fn_demographics).rename(columns={'id_author':'id_author_oa'})\n",
    "    df_nobel = pd.read_csv(fn_nobel_prize_winners, sep=';')\n",
    "    df_nobel.loc[:,'Fullname'] = df_nobel.apply(lambda row: f\"{row.Firstname} {row.Surname}\", axis=1)\n",
    "    df_nobel.rename(columns={'Surname':'last_name'}, inplace=True)\n",
    "\n",
    "    # keeping only necesary colums\n",
    "    cols_to_remove = ['created_date', 'updated_date', 'gender_nq', 'ethnicity_dx', 'ethnicity_ec']\n",
    "    df_demographics.drop(columns=cols_to_remove, inplace=True)\n",
    "    df_demographics.set_index('id_author_oa', inplace=True)\n",
    "\n",
    "    # adding nobel prize tag\n",
    "    column_block = 'last_name'\n",
    "    column_pairs = [(\"Fullname\", \"display_name\",\"jarowinkler\",0.85,\"display_name\"),\n",
    "                    (\"Fullname\", \"longest_name\",\"jarowinkler\",0.85,\"d_longest_name\"),\n",
    "                    (\"Fullname\", \"alternative_names\",\"jarowinkler\",0.7,\"d_alternative_names\"),\n",
    "                    (\"Firstname\", \"first_name\",\"jarowinkler\",0.7,\"first_name\"),\n",
    "                    (\"last_name\", \"last_name\",\"jarowinkler\",0.7,\"last_name\"),\n",
    "                    (\"Fullname\", \"last_name\",\"jarowinkler\",0.7,\"d_last_name\"),\n",
    "                    (\"Fullname\", \"first_name\",\"jarowinkler\",0.7,\"d_first_name\"),\n",
    "                    ]\n",
    "    valid_matches = text.find_matching_texts(df_nobel, df_demographics, \n",
    "                                             column_block=column_block, column_pairs_to_evaluate=column_pairs, threshold=threshold)\n",
    "    valid_matches.set_index('id_author_oa', inplace=True)\n",
    "\n",
    "    # adding new information (mapping)\n",
    "    df_demographics = df_demographics.join(valid_matches[['total_matches']], how='left')\n",
    "    df_demographics.rename(columns={\"total_matches\": \"nobel_prize_likelihood\"}, inplace=True)\n",
    "    df_demographics.loc[:, 'nobel_prize_likelihood'] = df_demographics.nobel_prize_likelihood / len(column_pairs)\n",
    "    \n",
    "    df_demographics = df_demographics.reset_index().drop_duplicates(subset='id_author_oa').set_index('id_author_oa')\n",
    "    return df_demographics\n",
    "\n",
    "def get_stats(fn_aps_stats, fn_oa_stats):\n",
    "    df_aps_stats = pd.read_csv(fn_aps_stats).rename(columns={'id_author':'id_author_oa'}).set_index('id_author_oa')\n",
    "    df_oa_stats = pd.read_csv(fn_oa_stats).rename(columns={'id_author':'id_author_oa'}).drop(columns=['created_date', 'updated_date', 'ID', 'name']).set_index('id_author_oa')\n",
    "\n",
    "    print(f\"APS stats data: {df_aps_stats.shape}\")\n",
    "    print(f\"OA stats data: {df_oa_stats.shape}\")\n",
    "\n",
    "    df_stats = df_oa_stats.join(df_aps_stats)\n",
    "\n",
    "    cols_order = sorted([c for c in df_oa_stats.columns if not c.startswith('rr')]) + [c for c in df_oa_stats.columns if c.startswith('rr')]\n",
    "    df_oa_stats = df_oa_stats[cols_order]\n",
    "\n",
    "    cols_order = ['orcid'] + df_aps_stats.columns.tolist() + [c for c in df_oa_stats.columns.tolist() if c!='orcid']\n",
    "    df_stats = df_stats[cols_order]\n",
    "    \n",
    "    #id_author,aps_works_count,aps_cited_by_count,aps_h_index,aps_i10_index,aps_e_index,aps_years_of_activity,aps_career_age,aps_citations_per_paper_age\n",
    "    #id_author,created_date,updated_date,name,orcid,two_year_mean_citedness,h_index,i10_index,works_count,cited_by_count,ID,e_index,career_age,max_year,min_year,citations_per_paper_age,rr1_rank_publications,rr1_rank_publications_percentile,rr2_rank_citations,rr2_rank_citations_percentile,rr3_rank_h_index,rr3_rank_h_index_percentile,rr4_rank_i10_index,rr4_rank_i10_index_percentile,rr5_rank_e_index,rr5_rank_e_index_percentile,rr6_rank_citation_publication_age,rr6_rank_citation_publication_age_percentile,rr7_rank_mean_citedness_2yr,rr7_rank_mean_citedness_2yr_percentile\n",
    "\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43470706",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f14db2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481012, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demographics (all authors)\n",
    "fn_demographics = io.path_join(APS_PATH, 'results/augmented_aps/authors_demographics.csv')\n",
    "fn_nobel_prize_winners = io.path_join(RESULTS, 'extra', 'nobel-prize-laureates.csv')\n",
    "df_demographics = get_demographics(fn_demographics, fn_nobel_prize_winners)\n",
    "df_demographics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58be2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics (only subset)\n",
    "df_demographics_sample = df_demographics.query(\"id_author_oa in @authors\").copy()\n",
    "fn = io.path_join(RESULTS, 'ground_truth', f'authors_demographics.csv')\n",
    "io.validate_path(fn)\n",
    "df_demographics_sample.to_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caeaa1",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7a8caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APS stats data: (481012, 8)\n",
      "OA stats data: (481012, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(481012, 33)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stats (all authors)\n",
    "fn_aps_stats = io.path_join(APS_PATH, 'results/augmented_aps/authors_aps_stats.csv')\n",
    "fn_oa_stats = io.path_join(APS_PATH, 'results/augmented_aps/authors_stats.csv')\n",
    "\n",
    "df_stats = get_stats(fn_aps_stats, fn_oa_stats)\n",
    "df_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66bece49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 33, now: 17\n"
     ]
    }
   ],
   "source": [
    "# PCA (all authors)\n",
    "df_PCA, df_PCA_summary = get_PCA(df_stats, n_components=2)\n",
    "\n",
    "# saving PCA reduced dimensions per author (all authors)\n",
    "fn = os.path.join(RESULTS, 'ground_truth', f'authors_PCA.csv')\n",
    "df_PCA['reduction'][['dim1','dim2']].to_csv(fn)\n",
    "\n",
    "# saving summary\n",
    "df_PCA_summary_final = pd.concat([df_PCA_summary, pd.DataFrame(index=['variance','variance_ratio'], columns=['PC1', 'PC2'], data=[df_PCA['variance'], df_PCA['variance_ratio']])])\n",
    "fn = io.path_join(RESULTS, 'ground_truth', f'summary_PCA.csv')\n",
    "io.validate_path(fn)\n",
    "df_PCA_summary_final.to_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7dcf067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61475, 33)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stats (only subset)\n",
    "df_stats_sample = df_stats.query(\"id_author_oa in @authors\").copy()\n",
    "fn = io.path_join(RESULTS, 'ground_truth', f'authors_stats.csv')\n",
    "io.validate_path(fn)\n",
    "df_stats_sample.to_csv(fn)\n",
    "\n",
    "df_stats_sample.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_llmscholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
