{
  "global": {
    "output_dir": "experiments"
  },
  "deepseek-chat-v3.1": {
    "model": "deepseek/deepseek-chat-v3.1:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 163800,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "deepseek-r1": {
    "model": "deepseek/deepseek-r1:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 8192,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "qwen3-235b": {
    "model": "qwen/qwen3-235b-a22b:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 8192,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "gemini-2.0-flash": {
    "model": "google/gemini-2.0-flash-exp:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 8192,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "llama-3.3-70b": {
    "model": "meta-llama/llama-3.3-70b-instruct:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 8192,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "llama-3.1-405b": {
    "model": "meta-llama/llama-3.1-405b-instruct:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 8192,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "mistral-small-3.2": {
    "model": "mistralai/mistral-small-3.2-24b-instruct:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 8192,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "gpt-oss-20b": {
    "model": "openai/gpt-oss-20b:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 8192,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "gemma-3-27b": {
    "model": "google/gemma-3-27b-it:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 8192,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "llama-3.3-8b": {
    "model": "meta-llama/llama-3.3-8b-instruct:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 4000,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  },
  "qwen3-8b": {
    "model": "qwen/qwen3-8b:free",
    "max_attempts": 3,
    "temperature": 0,
    "max_tokens": 41000,
    "stop": null,
    "stream": false,
    "system_message_ref": "physics_research_assistant"
  }
}