{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d63f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# =============================================================================\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
    "from google.oauth2 import service_account\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671f4c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: fengroland\n",
      "Location: us-central1\n",
      "Model: gemini-2.0-flash\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION LOADING\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "config = ConfigParser()\n",
    "KEYS_DIRECTORY = '/Volumes/T7 Shield/.keys' # so is not accessible by my LLM in the IDE\n",
    "config.read(os.path.join(KEYS_DIRECTORY, 'config.ini'))\n",
    "\n",
    "PROJECT_ID = config.get('google', 'project_id')\n",
    "LOCATION = config.get('google', 'location')\n",
    "MODEL_NAME = config.get('google', 'default_model')\n",
    "\n",
    "service_account_filename = config.get('google', 'service_account_file')\n",
    "if not os.path.isabs(service_account_filename):\n",
    "    SERVICE_ACCOUNT_FILE = os.path.join(KEYS_DIRECTORY, service_account_filename)\n",
    "else:\n",
    "    SERVICE_ACCOUNT_FILE = service_account_filename\n",
    "\n",
    "USER_PROMPT = \"Provide a list of statistical twins of Albert Laszlo Barabasi in JSON format\"\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Location: {LOCATION}\")\n",
    "print(f\"Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819a5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def generate_text_normal(prompt: str, temperature: float = 0.9, max_tokens: int = 1024) -> str:\n",
    "    \"\"\"Generate text using normal Vertex AI (no grounding)\"\"\"\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)\n",
    "        vertexai.init(project=PROJECT_ID, location=LOCATION, credentials=credentials)\n",
    "        \n",
    "        model = GenerativeModel(MODEL_NAME)\n",
    "        generation_config = GenerationConfig(temperature=temperature, max_output_tokens=max_tokens)\n",
    "        \n",
    "        response = model.generate_content(prompt, generation_config=generation_config)\n",
    "        \n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            return response.candidates[0].content.parts[0].text\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Normal generation error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def generate_text_grounded(prompt: str, temperature: float = 1.0, max_tokens: int = 1024) -> dict:\n",
    "    \"\"\"Generate text using Google Search grounding\"\"\"\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)\n",
    "        scoped_credentials = credentials.with_scopes(['https://www.googleapis.com/auth/cloud-platform'])\n",
    "\n",
    "        api_url = (\n",
    "            f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/\"\n",
    "            f\"{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{MODEL_NAME}:generateContent\"\n",
    "        )\n",
    "        \n",
    "        payload = {\n",
    "            \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}],\n",
    "            \"tools\": [{\"googleSearch\": {}}],\n",
    "            \"generationConfig\": {\"temperature\": temperature, \"maxOutputTokens\": max_tokens}\n",
    "        }\n",
    "        \n",
    "        session = AuthorizedSession(scoped_credentials)\n",
    "        response = session.post(api_url, headers={\"Content-Type\": \"application/json\"}, \n",
    "                              data=json.dumps(payload))\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Grounded generation error: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239805b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating normal response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barolo/LLMScholar-Audits/.venv/lib/python3.13/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n",
      "E0000 00:00:1758451552.338279 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Generating grounded response...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TESTING BOTH APPROACHES\n",
    "# =============================================================================\n",
    "print(\"üîÑ Generating normal response...\")\n",
    "normal_result = generate_text_normal(USER_PROMPT)\n",
    "\n",
    "print(\"üîç Generating grounded response...\")\n",
    "grounded_result = generate_text_grounded(USER_PROMPT)\n",
    "\n",
    "# Extract text from grounded result\n",
    "grounded_text = \"\"\n",
    "sources = []\n",
    "search_queries = []\n",
    "\n",
    "if grounded_result and 'candidates' in grounded_result:\n",
    "    candidate = grounded_result['candidates'][0]\n",
    "    if 'content' in candidate and 'parts' in candidate['content']:\n",
    "        grounded_text = candidate['content']['parts'][0]['text']\n",
    "    \n",
    "    # Extract grounding info\n",
    "    if 'groundingMetadata' in candidate:\n",
    "        metadata = candidate['groundingMetadata']\n",
    "        search_queries = metadata.get('webSearchQueries', [])\n",
    "        grounding_chunks = metadata.get('groundingChunks', [])\n",
    "        sources = [chunk.get('web', {}).get('uri', '') for chunk in grounding_chunks if 'web' in chunk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b5ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìã RESULTS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üîπ NORMAL RESPONSE (3737 chars)\n",
      "--------------------------------------------------\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Duncan Watts\",\n",
      "    \"institution\": \"University of Pennsylvania\",\n",
      "    \"field\": \"Sociology, Network Science\",\n",
      "    \"similarities\": [\n",
      "      \"Pioneering work on small-world networks.\",\n",
      "      \"Application of network science to social phenomena.\",\n",
      "      \"Author of influential books on complexity and social systems.\",\n",
      "      \"Highly cited researcher in network science and related fields.\",\n",
      "      \"Emphasis on data-driven approaches to understanding complex systems.\",\n",
      "      \"Consulting and advising roles in industry and government.\"\n",
      "    ],\n",
      "    \"differences\": [\n",
      "      \"Watts has a stronger background in sociology and social dynamics.\",\n",
      "      \"Barabasi's early work focused more on scale-free networks in physics and biology.\",\n",
      "      \"Watts' research often emphasizes the role of individual agency and social influence.\"\n",
      "    ],\n",
      "    \"justification\": \"Both Watts and Barabasi are considered foundational figures in the development of network science. They both made seminal contributions to our understanding of small-world networks and their implications for social and technological systems. Their research has had a significant impact across multiple disciplines, including sociology, physics, and computer science.\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Mark Newman\",\n",
      "    \"institution\": \"University of Michigan\",\n",
      "    \"field\": \"Physics, Network Science\",\n",
      "    \"similarities\": [\n",
      "      \"Significant contributions to the development of community detection algorithms in networks.\",\n",
      "      \"Research on the structure and dynamics of real-world networks.\",\n",
      "      \"Author of influential textbooks on network science.\",\n",
      "      \"Strong physics background applied to network analysis.\",\n",
      "      \"Mathematical and computational modeling of network phenomena.\"\n",
      "    ],\n",
      "    \"differences\": [\n",
      "      \"Newman's work is generally more focused on methodological and computational aspects of network analysis.\",\n",
      "      \"Barabasi's work often emphasizes the impact of network structure on dynamical processes.\",\n",
      "      \"Newman's research has a stronger emphasis on statistical inference in networks.\"\n",
      "    ],\n",
      "    \"justification\": \"Newman, like Barabasi, is a leading researcher in network science with a background in physics. He is known for his methodological contributions to network analysis, particularly in the area of community detection. Both researchers have made significant contributions to our understanding of the statistical properties of real-world networks.\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Guido Caldarelli\",\n",
      "    \"institution\": \"University College London\",\n",
      "    \"field\": \"Physics, Network Science, Economics\",\n",
      "    \"similarities\": [\n",
      "      \"Application of network science to economic and financial systems.\",\n",
      "      \"Research on the systemic risk in financial networks.\",\n",
      "      \"Interdisciplinary approach combining physics, economics, and computer science.\",\n",
      "      \"Work on the evolution and dynamics of networks.\",\n",
      "      \"Focus on the role of network structure in shaping economic outcomes.\"\n",
      "    ],\n",
      "    \"differences\": [\n",
      "      \"Caldarelli's research has a stronger focus on economic and financial applications.\",\n",
      "      \"Barabasi's work has a broader scope, encompassing biological and technological networks.\",\n",
      "      \"Caldarelli's research often involves more specific economic models and theories.\"\n",
      "    ],\n",
      "    \"justification\": \"Caldarelli shares Barabasi's interdisciplinary approach and his use of network science to understand complex systems. Caldarelli's work specifically examines the intersection of network science and economics, similar to how Barabasi has explored its intersection with other fields. Both researchers have significantly contributed to understanding the dynamics of complex networks and their impact on various domains.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "\n",
      "üîç GROUNDED RESPONSE (1029 chars)\n",
      "--------------------------------------------------\n",
      "I need more information to provide you with a list of statistical twins of Albert Laszlo Barabasi in JSON format.\n",
      "\n",
      "Here's what I need to know:\n",
      "\n",
      "*   **What characteristics define a \"statistical twin\" in this context?** Are you looking for people with similar publication records, citation patterns, research areas, co-author networks, or something else? The definition of \"statistical twin\" is crucial for identifying appropriate individuals.\n",
      "*   **What data sources should be used to find these twins?** Should I search publication databases like Web of Science or Scopus, collaboration networks like DBLP, or other sources?\n",
      "*   **What level of similarity is required?** How closely should the statistical twins match Barabasi's characteristics?\n",
      "\n",
      "Once I have this information, I can formulate appropriate search queries and provide you with a relevant JSON output.\n",
      "\n",
      "For example, if you define \"statistical twins\" as researchers with similar publication and citation records in network science, I could use the following queries:\n",
      "\n",
      "\n",
      "üîé SEARCH QUERIES USED:\n",
      "  ‚Ä¢ Albert Laszlo Barabasi co-authors\n",
      "  ‚Ä¢ researchers with similar publication records to Albert Laszlo Barabasi in network science\n",
      "  ‚Ä¢ citation analysis of Albert Laszlo Barabasi\n",
      "  ‚Ä¢ citation analysis of network science researchers\n",
      "  ‚Ä¢ network science collaboration networks\n",
      "  ‚Ä¢ top researchers in network science\n",
      "  ‚Ä¢ influential network science researchers\n",
      "\n",
      "üìä SUMMARY:\n",
      "  Normal response:  3,737 characters\n",
      "  Grounded response: 1,029 characters\n",
      "  Sources used: 0\n",
      "  Search queries: 7\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RESULTS COMPARISON\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üìã RESULTS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüîπ NORMAL RESPONSE ({len(normal_result)} chars)\")\n",
    "print(\"-\" * 50)\n",
    "print(normal_result)\n",
    "\n",
    "print(f\"\\nüîç GROUNDED RESPONSE ({len(grounded_text)} chars)\")\n",
    "print(\"-\" * 50)\n",
    "print(grounded_text)\n",
    "\n",
    "if search_queries:\n",
    "    print(f\"\\nüîé SEARCH QUERIES USED:\")\n",
    "    for query in search_queries:\n",
    "        print(f\"  ‚Ä¢ {query}\")\n",
    "\n",
    "if sources:\n",
    "    print(f\"\\nüìö SOURCES ({len(sources)}):\")\n",
    "    for i, source in enumerate(sources[:5], 1):  # Show first 5 sources\n",
    "        print(f\"  {i}. {source}\")\n",
    "\n",
    "print(f\"\\nüìä SUMMARY:\")\n",
    "print(f\"  Normal response:  {len(normal_result):,} characters\")\n",
    "print(f\"  Grounded response: {len(grounded_text):,} characters\")\n",
    "print(f\"  Sources used: {len(sources)}\")\n",
    "print(f\"  Search queries: {len(search_queries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301c4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing prompt: Provide a list of statistical twins of Albert Laszlo Barabas...\n",
      "================================================================================\n",
      "\n",
      "üîÑ Testing gemini-2.5-pro...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758452219.760581 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìù Normal: 1038 chars\n",
      "  üîç Grounded: 994 chars (4 sources, 3 queries)\n",
      "\n",
      "üîÑ Testing gemini-2.5-flash...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758452227.725970 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìù Normal: 1143 chars\n",
      "  üîç Grounded: 419 chars (9 sources, 3 queries)\n",
      "\n",
      "üîÑ Testing gemini-2.5-flash-lite...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758452235.610786 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìù Normal: 1265 chars\n",
      "  üîç Grounded: 952 chars (0 sources, 1 queries)\n",
      "\n",
      "üîÑ Testing gemini-2.0-flash...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758452242.037945 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìù Normal: 1059 chars\n",
      "  üîç Grounded: 741 chars (6 sources, 3 queries)\n",
      "\n",
      "üîÑ Testing gemini-2.0-flash-lite...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758452250.359043 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìù Normal: 1069 chars\n",
      "  üîç Grounded: 614 chars (4 sources, 4 queries)\n",
      "\n",
      "================================================================================\n",
      "üìä SUMMARY TABLE\n",
      "================================================================================\n",
      "Model                Normal   Grounded   Sources  Status\n",
      "--------------------------------------------------------------------------------\n",
      "gemini-2.5-pro       1038     994        4        ‚úÖ / ‚úÖ\n",
      "gemini-2.5-flash     1143     419        9        ‚úÖ / ‚úÖ\n",
      "gemini-2.5-flash-lite 1265     952        0        ‚úÖ / ‚úÖ\n",
      "gemini-2.0-flash     1059     741        6        ‚úÖ / ‚úÖ\n",
      "gemini-2.0-flash-lite 1069     614        4        ‚úÖ / ‚úÖ\n",
      "\n",
      "================================================================================\n",
      "üìã DETAILED RESPONSES (First 200 chars)\n",
      "================================================================================\n",
      "\n",
      "üîπ GEMINI-2.5-PRO\n",
      "--------------------------------------------------\n",
      "Normal: ```json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Duncan Watts\",\n",
      "    \"fields\": [\n",
      "      \"Network Science\",\n",
      "      \"Small-World Networks\",\n",
      "      \"Social Networks\",\n",
      "      \"Collective Behavior\",\n",
      "      \"Complexity Science\"\n",
      "    ],...\n",
      "Grounded: I need more information to provide you with a list of Albert Laszlo Barabasi's statistical twins in JSON format. I don't have enough information about what constitutes a \"statistical twin\" in this con...\n",
      "üìö Used 4 sources, 3 queries\n",
      "\n",
      "üîπ GEMINI-2.5-FLASH\n",
      "--------------------------------------------------\n",
      "Normal: ```json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Duncan J. Watts\",\n",
      "    \"reason\": \"Watts, like Barabasi, is a physicist turned network scientist. He is known for his work on small-world networks and collective behavior, oft...\n",
      "Grounded: I need more information to provide a list of statistical twins of Albert Laszlo Barabasi in JSON format. Please provide details on what characteristics to consider when identifying statistical twins. ...\n",
      "üìö Used 9 sources, 3 queries\n",
      "\n",
      "üîπ GEMINI-2.5-FLASH-LITE\n",
      "--------------------------------------------------\n",
      "Normal: ```json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Duncan J. Watts\",\n",
      "    \"description\": \"A sociologist and network scientist known for his work on small-world networks, collective dynamics, and computational social science. ...\n",
      "Grounded: I need more information to assist you with your request. Specifically, I need to know what criteria define a \"statistical twin\" in this context. What characteristics or data points about Albert Laszlo...\n",
      "\n",
      "üîπ GEMINI-2.0-FLASH\n",
      "--------------------------------------------------\n",
      "Normal: ```json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Duncan Watts\",\n",
      "    \"description\": \"A sociologist and network scientist known for his work on small-world networks and collective dynamics. His research overlaps with Barabas...\n",
      "Grounded: I need more information to provide you with a list of statistical twins of Albert Laszlo Barabasi in JSON format.\n",
      "\n",
      "To find statistical twins, I need to know what characteristics or data points to use ...\n",
      "üìö Used 6 sources, 3 queries\n",
      "\n",
      "üîπ GEMINI-2.0-FLASH-LITE\n",
      "--------------------------------------------------\n",
      "Normal: ```json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Duncan J. Watts\",\n",
      "    \"fields\": [\n",
      "      \"Network Science\",\n",
      "      \"Social Networks\",\n",
      "      \"Collective Behavior\",\n",
      "      \"Computational Social Science\"\n",
      "    ],\n",
      "    \"similaritie...\n",
      "Grounded: I need more information to create a list of statistical twins of Albert Laszlo Barabasi in JSON format. Please clarify what criteria should be used to identify statistical twins. For example:\n",
      "\n",
      "*   Whi...\n",
      "üìö Used 4 sources, 4 queries\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST ALL AVAILABLE GEMINI MODELS\n",
    "# =============================================================================\n",
    "\n",
    "# Available Gemini models on Vertex AI (as of September 2025)\n",
    "GEMINI_MODELS = [\n",
    "    \"gemini-2.5-pro\",         # Most advanced reasoning model\n",
    "    \"gemini-2.5-flash\",       # Best price-performance \n",
    "    \"gemini-2.5-flash-lite\",  # Most cost effective, high throughput\n",
    "    \"gemini-2.0-flash\",       # Newest multimodal model\n",
    "    \"gemini-2.0-flash-lite\",  # Cost efficient, low latency\n",
    "]\n",
    "\n",
    "def test_all_models(prompt: str, max_tokens: int = 256):\n",
    "    \"\"\"Test the same prompt on all available Gemini models, with and without grounding\"\"\"\n",
    "    \n",
    "    print(f\"üß™ Testing prompt: {prompt[:60]}...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model in GEMINI_MODELS:\n",
    "        print(f\"\\nüîÑ Testing {model}...\")\n",
    "        \n",
    "        # Test normal version\n",
    "        try:\n",
    "            normal_result = generate_text_normal(prompt, temperature=0.9, max_tokens=max_tokens)\n",
    "            normal_length = len(normal_result)\n",
    "        except Exception as e:\n",
    "            normal_result = f\"ERROR: {e}\"\n",
    "            normal_length = 0\n",
    "        \n",
    "        # Test grounded version (only works with certain models)\n",
    "        try:\n",
    "            grounded_data = generate_text_grounded(prompt, temperature=1.0, max_tokens=max_tokens)\n",
    "            if grounded_data and 'candidates' in grounded_data:\n",
    "                grounded_result = grounded_data['candidates'][0]['content']['parts'][0]['text']\n",
    "                grounded_length = len(grounded_result)\n",
    "                \n",
    "                # Count sources\n",
    "                metadata = grounded_data['candidates'][0].get('groundingMetadata', {})\n",
    "                sources_count = len(metadata.get('groundingChunks', []))\n",
    "                queries_count = len(metadata.get('webSearchQueries', []))\n",
    "            else:\n",
    "                grounded_result = \"ERROR: No response\"\n",
    "                grounded_length = 0\n",
    "                sources_count = 0\n",
    "                queries_count = 0\n",
    "        except Exception as e:\n",
    "            grounded_result = f\"ERROR: {e}\"\n",
    "            grounded_length = 0\n",
    "            sources_count = 0\n",
    "            queries_count = 0\n",
    "        \n",
    "        # Store results\n",
    "        results[model] = {\n",
    "            'normal': normal_result,\n",
    "            'normal_length': normal_length,\n",
    "            'grounded': grounded_result,\n",
    "            'grounded_length': grounded_length,\n",
    "            'sources': sources_count,\n",
    "            'queries': queries_count\n",
    "        }\n",
    "        \n",
    "        # Quick summary\n",
    "        print(f\"  üìù Normal: {normal_length} chars\")\n",
    "        print(f\"  üîç Grounded: {grounded_length} chars ({sources_count} sources, {queries_count} queries)\")\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä SUMMARY TABLE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Model':<20} {'Normal':<8} {'Grounded':<10} {'Sources':<8} {'Status'}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for model, data in results.items():\n",
    "        normal_ok = \"‚úÖ\" if data['normal_length'] > 0 else \"‚ùå\"\n",
    "        grounded_ok = \"‚úÖ\" if data['grounded_length'] > 0 else \"‚ùå\"\n",
    "        status = f\"{normal_ok} / {grounded_ok}\"\n",
    "        \n",
    "        print(f\"{model:<20} {data['normal_length']:<8} {data['grounded_length']:<10} \"\n",
    "              f\"{data['sources']:<8} {status}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Quick test with your prompt\n",
    "results = test_all_models(USER_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f237817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing concurrent execution of 6 Gemini models...\n",
      "üöÄ Launching 6 concurrent calls...\n",
      "üîÑ Starting gemini-2.5-pro (normal)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758473430.554771 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ gemini-2.5-pro (normal): 576 chars\n",
      "üîç Starting gemini-2.5-pro (grounded)...\n",
      "‚úÖ gemini-2.5-pro (grounded): 297 chars\n",
      "üîÑ Starting gemini-2.5-flash (normal)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758473436.239340 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ gemini-2.5-flash (normal): 575 chars\n",
      "üîç Starting gemini-2.5-flash (grounded)...\n",
      "‚úÖ gemini-2.5-flash (grounded): 297 chars\n",
      "üîÑ Starting gemini-2.5-flash-lite (normal)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758473441.514445 8335524 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ gemini-2.5-flash-lite (normal): 575 chars\n",
      "üîç Starting gemini-2.5-flash-lite (grounded)...\n",
      "‚úÖ gemini-2.5-flash-lite (grounded): 282 chars\n",
      "\n",
      "üìä CONCURRENT TEST RESULTS:\n",
      "   Total time: 16.8 seconds\n",
      "   Average per call: 2.8 seconds\n",
      "   Success rate: 6/6 calls\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONCURRENT GEMINI TEST - 6 Models with Same Prompt\n",
    "# =============================================================================\n",
    "\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# Define all 6 models\n",
    "GEMINI_MODELS_TEST = [\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.5-flash-lite\"\n",
    "]\n",
    "\n",
    "TEST_PROMPT = \"List 3 famous physicists in JSON format\"\n",
    "\n",
    "async def test_concurrent_gemini():\n",
    "    \"\"\"Test if we can run all 6 Gemini variants concurrently\"\"\"\n",
    "\n",
    "    print(\"üß™ Testing concurrent execution of 6 Gemini models...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    async def call_normal_model(model_name):\n",
    "        print(f\"üîÑ Starting {model_name} (normal)...\")\n",
    "        try:\n",
    "            result = generate_text_normal(TEST_PROMPT, temperature=0, max_tokens=200)\n",
    "            print(f\"‚úÖ {model_name} (normal): {len(result)} chars\")\n",
    "            return f\"{model_name}-normal\", result\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {model_name} (normal): {e}\")\n",
    "            return f\"{model_name}-normal\", f\"ERROR: {e}\"\n",
    "\n",
    "    async def call_grounded_model(model_name):\n",
    "        print(f\"üîç Starting {model_name} (grounded)...\")\n",
    "        try:\n",
    "            result = generate_text_grounded(TEST_PROMPT, temperature=0, max_tokens=200)\n",
    "            if result and 'candidates' in result:\n",
    "                text = result['candidates'][0]['content']['parts'][0]['text']\n",
    "                print(f\"‚úÖ {model_name} (grounded): {len(text)} chars\")\n",
    "                return f\"{model_name}-grounded\", text\n",
    "            else:\n",
    "                print(f\"‚ùå {model_name} (grounded): No response\")\n",
    "                return f\"{model_name}-grounded\", \"No response\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {model_name} (grounded): {e}\")\n",
    "            return f\"{model_name}-grounded\", f\"ERROR: {e}\"\n",
    "\n",
    "    # Create all 6 tasks (3 models √ó 2 variants each)\n",
    "    tasks = []\n",
    "    for model in GEMINI_MODELS_TEST:\n",
    "        tasks.append(call_normal_model(model))\n",
    "        tasks.append(call_grounded_model(model))\n",
    "\n",
    "    print(f\"üöÄ Launching {len(tasks)} concurrent calls...\")\n",
    "\n",
    "    # Run all concurrently\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    print(f\"\\nüìä CONCURRENT TEST RESULTS:\")\n",
    "    print(f\"   Total time: {total_time:.1f} seconds\")\n",
    "    print(f\"   Average per call: {total_time/len(tasks):.1f} seconds\")\n",
    "\n",
    "    success_count = 0\n",
    "    for result in results:\n",
    "        if isinstance(result, tuple) and not result[1].startswith(\"ERROR\"):\n",
    "            success_count += 1\n",
    "\n",
    "    print(f\"   Success rate: {success_count}/{len(tasks)} calls\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run the test\n",
    "results = await test_concurrent_gemini()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5dcb5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gemini-2.5-pro-normal',\n",
       "  '```json\\n[\\n  {\\n    \"name\": \"Albert Einstein\",\\n    \"field\": \"Theoretical Physics\",\\n    \"known_for\": \"Theory of Relativity, E=mc¬≤, Photoelectric Effect\",\\n    \"nationality\": \"German, Swiss, American\"\\n  },\\n  {\\n    \"name\": \"Isaac Newton\",\\n    \"field\": \"Classical Mechanics, Optics, Calculus\",\\n    \"known_for\": \"Laws of Motion, Law of Universal Gravitation, Calculus\",\\n    \"nationality\": \"English\"\\n  },\\n  {\\n    \"name\": \"Marie Curie\",\\n    \"field\": \"Physics, Chemistry\",\\n    \"known_for\": \"Radioactivity, Discovery of Polonium and Radium\",\\n    \"nationality\": \"Polish, French\"\\n  }\\n]\\n```\\n'),\n",
       " ('gemini-2.5-pro-grounded',\n",
       "  '```json\\n[\\n  {\\n    \"name\": \"Albert Einstein\",\\n    \"known_for\": \"Theory of Relativity, Photoelectric Effect\"\\n  },\\n  {\\n    \"name\": \"Isaac Newton\",\\n    \"known_for\": \"Laws of Motion, Universal Gravitation\"\\n  },\\n  {\\n    \"name\": \"Niels Bohr\",\\n    \"known_for\": \"Atomic Structure, Quantum Theory\"\\n  }\\n]\\n```'),\n",
       " ('gemini-2.5-flash-normal',\n",
       "  '```json\\n[\\n  {\\n    \"name\": \"Albert Einstein\",\\n    \"field\": \"Theoretical Physics\",\\n    \"known_for\": \"Theory of Relativity, E=mc¬≤, Photoelectric Effect\",\\n    \"nationality\": \"German, Swiss, American\"\\n  },\\n  {\\n    \"name\": \"Isaac Newton\",\\n    \"field\": \"Classical Mechanics, Optics, Calculus\",\\n    \"known_for\": \"Laws of Motion, Law of Universal Gravitation, Calculus\",\\n    \"nationality\": \"English\"\\n  },\\n  {\\n    \"name\": \"Marie Curie\",\\n    \"field\": \"Physics, Chemistry\",\\n    \"known_for\": \"Radioactivity, Discovery of Polonium and Radium\",\\n    \"nationality\": \"Polish, French\"\\n  }\\n]\\n```'),\n",
       " ('gemini-2.5-flash-grounded',\n",
       "  '```json\\n[\\n  {\\n    \"name\": \"Albert Einstein\",\\n    \"known_for\": \"Theory of Relativity, Photoelectric Effect\"\\n  },\\n  {\\n    \"name\": \"Isaac Newton\",\\n    \"known_for\": \"Laws of Motion, Universal Gravitation\"\\n  },\\n  {\\n    \"name\": \"Niels Bohr\",\\n    \"known_for\": \"Atomic Structure, Quantum Theory\"\\n  }\\n]\\n```'),\n",
       " ('gemini-2.5-flash-lite-normal',\n",
       "  '```json\\n[\\n  {\\n    \"name\": \"Albert Einstein\",\\n    \"field\": \"Theoretical Physics\",\\n    \"known_for\": \"Theory of Relativity, E=mc¬≤, Photoelectric Effect\",\\n    \"nationality\": \"German, Swiss, American\"\\n  },\\n  {\\n    \"name\": \"Isaac Newton\",\\n    \"field\": \"Classical Mechanics, Optics, Calculus\",\\n    \"known_for\": \"Laws of Motion, Law of Universal Gravitation, Calculus\",\\n    \"nationality\": \"English\"\\n  },\\n  {\\n    \"name\": \"Marie Curie\",\\n    \"field\": \"Physics, Chemistry\",\\n    \"known_for\": \"Radioactivity, Discovery of Polonium and Radium\",\\n    \"nationality\": \"Polish, French\"\\n  }\\n]\\n```'),\n",
       " ('gemini-2.5-flash-lite-grounded',\n",
       "  '```json\\n[\\n  {\\n    \"name\": \"Albert Einstein\",\\n    \"known_for\": \"Theory of Relativity, E=mc2\"\\n  },\\n  {\\n    \"name\": \"Isaac Newton\",\\n    \"known_for\": \"Laws of Motion, Universal Gravitation\"\\n  },\\n  {\\n    \"name\": \"Niels Bohr\",\\n    \"known_for\": \"Atomic structure, Quantum theory\"\\n  }\\n]\\n```')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMScholar-Audits (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
