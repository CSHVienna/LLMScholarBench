{
  "test_info": {
    "timestamp": "20250927_134217",
    "total_models": 11,
    "temperatures_tested": [
      0.0,
      0.2631578947368421,
      0.5263157894736842,
      0.7894736842105263,
      1.0526315789473684,
      1.3157894736842104,
      1.5789473684210527,
      1.8421052631578947,
      2.1052631578947367,
      2.3684210526315788,
      2.631578947368421,
      2.894736842105263,
      3.1578947368421053,
      3.4210526315789473,
      3.6842105263157894,
      3.9473684210526314,
      4.2105263157894735,
      4.473684210526316,
      4.7368421052631575,
      5.0
    ],
    "models_tested": [
      "grok-4-fast",
      "llama-4-mav",
      "llama-3.3-8b",
      "qwen3-8b",
      "gpt-oss-20b",
      "mistral-small-3.2",
      "gemma-3-27b",
      "llama-3.3-70b",
      "qwen3-235b",
      "deepseek-chat-v3.1",
      "deepseek-r1"
    ]
  },
  "model_summaries": [
    {
      "model": "grok-4-fast",
      "total_tests": 20,
      "successful": 8,
      "failed": 12,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "grok-4-fast",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "grok-4-fast",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "grok-4-fast",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "grok-4-fast",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "grok-4-fast",
          "temperature": 1.0526315789473684,
          "success": true,
          "error": null
        },
        {
          "model": "grok-4-fast",
          "temperature": 1.3157894736842104,
          "success": true,
          "error": null
        },
        {
          "model": "grok-4-fast",
          "temperature": 1.5789473684210527,
          "success": true,
          "error": null
        },
        {
          "model": "grok-4-fast",
          "temperature": 1.8421052631578947,
          "success": true,
          "error": null
        },
        {
          "model": "grok-4-fast",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "grok-4-fast",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "llama-4-mav",
      "total_tests": 20,
      "successful": 4,
      "failed": 16,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "llama-4-mav",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "llama-4-mav",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "llama-4-mav",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "llama-4-mav",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "llama-4-mav",
          "temperature": 1.0526315789473684,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\"title\":\"Bad request\",\"detail\":\"Invalid \\'temperature\\': must be a float between 0.0 and 1.0\",\"status\":400}', 'provider_name': 'Meta'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 1.3157894736842104,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\"title\":\"Bad request\",\"detail\":\"Invalid \\'temperature\\': must be a float between 0.0 and 1.0\",\"status\":400}', 'provider_name': 'Meta'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 1.5789473684210527,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\"title\":\"Bad request\",\"detail\":\"Invalid \\'temperature\\': must be a float between 0.0 and 1.0\",\"status\":400}', 'provider_name': 'Meta'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 1.8421052631578947,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\"title\":\"Bad request\",\"detail\":\"Invalid \\'temperature\\': must be a float between 0.0 and 1.0\",\"status\":400}', 'provider_name': 'Meta'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-4-mav",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "llama-3.3-8b",
      "total_tests": 20,
      "successful": 4,
      "failed": 16,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "llama-3.3-8b",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 1.0526315789473684,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\"title\":\"Bad request\",\"detail\":\"Invalid \\'temperature\\': must be a float between 0.0 and 1.0\",\"status\":400}', 'provider_name': 'Meta'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 1.3157894736842104,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\"title\":\"Bad request\",\"detail\":\"Invalid \\'temperature\\': must be a float between 0.0 and 1.0\",\"status\":400}', 'provider_name': 'Meta'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 1.5789473684210527,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\"title\":\"Bad request\",\"detail\":\"Invalid \\'temperature\\': must be a float between 0.0 and 1.0\",\"status\":400}', 'provider_name': 'Meta'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 1.8421052631578947,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\"title\":\"Bad request\",\"detail\":\"Invalid \\'temperature\\': must be a float between 0.0 and 1.0\",\"status\":400}', 'provider_name': 'Meta'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-8b",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "qwen3-8b",
      "total_tests": 20,
      "successful": 8,
      "failed": 12,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "qwen3-8b",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-8b",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-8b",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-8b",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-8b",
          "temperature": 1.0526315789473684,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-8b",
          "temperature": 1.3157894736842104,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-8b",
          "temperature": 1.5789473684210527,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-8b",
          "temperature": 1.8421052631578947,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-8b",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-8b",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "gpt-oss-20b",
      "total_tests": 20,
      "successful": 8,
      "failed": 12,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "gpt-oss-20b",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 1.0526315789473684,
          "success": true,
          "error": null
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 1.3157894736842104,
          "success": true,
          "error": null
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 1.5789473684210527,
          "success": true,
          "error": null
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 1.8421052631578947,
          "success": true,
          "error": null
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gpt-oss-20b",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "mistral-small-3.2",
      "total_tests": 20,
      "successful": 8,
      "failed": 12,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "mistral-small-3.2",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 1.0526315789473684,
          "success": true,
          "error": null
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 1.3157894736842104,
          "success": true,
          "error": null
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 1.5789473684210527,
          "success": true,
          "error": null
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 1.8421052631578947,
          "success": true,
          "error": null
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "mistral-small-3.2",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "gemma-3-27b",
      "total_tests": 20,
      "successful": 8,
      "failed": 12,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "gemma-3-27b",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "gemma-3-27b",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "gemma-3-27b",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "gemma-3-27b",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "gemma-3-27b",
          "temperature": 1.0526315789473684,
          "success": true,
          "error": null
        },
        {
          "model": "gemma-3-27b",
          "temperature": 1.3157894736842104,
          "success": true,
          "error": null
        },
        {
          "model": "gemma-3-27b",
          "temperature": 1.5789473684210527,
          "success": true,
          "error": null
        },
        {
          "model": "gemma-3-27b",
          "temperature": 1.8421052631578947,
          "success": true,
          "error": null
        },
        {
          "model": "gemma-3-27b",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "gemma-3-27b",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "llama-3.3-70b",
      "total_tests": 20,
      "successful": 8,
      "failed": 12,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "llama-3.3-70b",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 1.0526315789473684,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 1.3157894736842104,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 1.5789473684210527,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 1.8421052631578947,
          "success": true,
          "error": null
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "llama-3.3-70b",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "qwen3-235b",
      "total_tests": 20,
      "successful": 8,
      "failed": 12,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "qwen3-235b",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-235b",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-235b",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-235b",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-235b",
          "temperature": 1.0526315789473684,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-235b",
          "temperature": 1.3157894736842104,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-235b",
          "temperature": 1.5789473684210527,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-235b",
          "temperature": 1.8421052631578947,
          "success": true,
          "error": null
        },
        {
          "model": "qwen3-235b",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "qwen3-235b",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "deepseek-chat-v3.1",
      "total_tests": 20,
      "successful": 8,
      "failed": 12,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 0.0,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 0.2631578947368421,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 0.5263157894736842,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 1.0526315789473684,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 1.3157894736842104,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 1.5789473684210527,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 1.8421052631578947,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-chat-v3.1",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    },
    {
      "model": "deepseek-r1",
      "total_tests": 20,
      "successful": 1,
      "failed": 19,
      "temperatures_tested": [
        0.0,
        0.2631578947368421,
        0.5263157894736842,
        0.7894736842105263,
        1.0526315789473684,
        1.3157894736842104,
        1.5789473684210527,
        1.8421052631578947,
        2.1052631578947367,
        2.3684210526315788,
        2.631578947368421,
        2.894736842105263,
        3.1578947368421053,
        3.4210526315789473,
        3.6842105263157894,
        3.9473684210526314,
        4.2105263157894735,
        4.473684210526316,
        4.7368421052631575,
        5.0
      ],
      "results": [
        {
          "model": "deepseek-r1",
          "temperature": 0.0,
          "success": false,
          "error": "Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '20', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1758974820000'}, 'provider_name': None}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 0.2631578947368421,
          "success": false,
          "error": "Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'deepseek/deepseek-r1:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Chutes'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 0.5263157894736842,
          "success": false,
          "error": "Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'deepseek/deepseek-r1:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Chutes'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 0.7894736842105263,
          "success": true,
          "error": null
        },
        {
          "model": "deepseek-r1",
          "temperature": 1.0526315789473684,
          "success": false,
          "error": "Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'deepseek/deepseek-r1:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Chutes'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 1.3157894736842104,
          "success": false,
          "error": "Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'deepseek/deepseek-r1:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Chutes'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 1.5789473684210527,
          "success": false,
          "error": "Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '20', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1758974820000'}, 'provider_name': None}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 1.8421052631578947,
          "success": false,
          "error": "Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'deepseek/deepseek-r1:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Chutes'}}, 'user_id': 'user_2ypJrHbIFm5lhnAMiYtfjHuP5uW'}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 2.1052631578947367,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.1052631578947367', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 2.3684210526315788,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.3684210526315788', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 2.631578947368421,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.631578947368421', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 2.894736842105263,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 2.894736842105263', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 3.1578947368421053,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.1578947368421053', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 3.4210526315789473,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.4210526315789473', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 3.6842105263157894,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.6842105263157894', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 3.9473684210526314,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 3.9473684210526314', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 4.2105263157894735,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.2105263157894735', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 4.473684210526316,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.473684210526316', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 4.7368421052631575,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 4.7368421052631575', 'code': 400, 'metadata': {'provider_name': None}}}"
        },
        {
          "model": "deepseek-r1",
          "temperature": 5.0,
          "success": false,
          "error": "Error code: 400 - {'error': {'message': 'Expected temperature to be at most 2, received 5', 'code': 400, 'metadata': {'provider_name': None}}}"
        }
      ]
    }
  ]
}